resources:
  jobs:
    integration_tests:
      name: integration_tests_${bundle.target}
      
      tasks:
        - task_key: run_integration_tests
          notebook_task:
            notebook_path: ../tests/test_workflow.py
            source: WORKSPACE
          job_cluster_key: test_cluster
      
      # Define cluster for tests
      job_clusters:
        - job_cluster_key: test_cluster
          new_cluster:
            spark_version: "13.3.x-scala2.12"
            node_type_id: "Standard_DS3_v2"
            num_workers: 1
            spark_conf:
              "spark.databricks.delta.preview.enabled": "true"
            custom_tags:
              ResourceClass: "Classic"
              purpose: "integration-testing"
      
      # Run tests on demand (not scheduled)
      max_concurrent_runs: 1
      
      # Timeout for tests (10 minutes)
      timeout_seconds: 600
      
      tags:
        environment: "${bundle.target}"
        project: "dab_demo"
        type: "integration_test"


